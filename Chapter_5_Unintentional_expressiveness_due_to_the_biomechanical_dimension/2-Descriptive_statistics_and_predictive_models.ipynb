{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0f51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import joblib\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae997ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_60 = pd.read_csv('Dataset_60_bpm_complete_CSV.csv', sep=\";\")\n",
    "df_80 = pd.read_csv('Dataset_80_bpm_complete_CSV.csv', sep=\";\")\n",
    "df_100 = pd.read_csv('Dataset_100_bpm_complete_CSV.csv', sep=\";\")\n",
    "df_120 = pd.read_csv('Dataset_120_bpm_complete_CSV.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0922b37d",
   "metadata": {},
   "source": [
    "## Add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc7d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_60['t_dt_note_on_ms'] = df_60['t_dt_note_on'] * (60 / df_60['bpm'] / 960)  * 1000\n",
    "df_60['t_dt_note_off_ms'] = df_60['t_dt_note_off'] * (60 / df_60['bpm'] / 960)  * 1000\n",
    "df_60['delta_onset_ms'] = np.rint((df_60['t_dt_note_on'] - df_60['t_dt_note_on_ref']) * (60 / df_60['bpm'] / 960)  * 1000)\n",
    "df_60['delta_onset_ms-1'] = df_60['delta_onset_ms'].shift(+1)\n",
    "df_60['delta_onset'] = df_60['t_dt_note_on'] - df_60['t_dt_note_on_ref']\n",
    "df_60['delta_onset-1'] = df_60['delta_onset'].shift(+1)\n",
    "df_60['prec_rest_ms'] = np.rint(df_60['prec_rest'] * (60 / df_60['bpm'] / 960)  * 1000)\n",
    "df_60['IOI_ms'] = np.rint(df_60['IOI'] * (60 / df_60['bpm'] / 960)  * 1000)\n",
    "df_60['PC-abs'] = df_60['PC'].abs()\n",
    "df_60['SC-abs'] = df_60['SC'].abs()\n",
    "df_60['velocity-1'] = df_60['velocity'].shift(+1)\n",
    "\n",
    "df_80['t_dt_note_on_ms'] = df_80['t_dt_note_on'] * (60 / df_80['bpm'] / 960)  * 1000\n",
    "df_80['t_dt_note_off_ms'] = df_80['t_dt_note_off'] * (60 / df_80['bpm'] / 960)  * 1000\n",
    "df_80['delta_onset_ms'] = np.rint((df_80['t_dt_note_on'] - df_80['t_dt_note_on_ref']) * (60 / df_80['bpm'] / 960)  * 1000)\n",
    "df_80['delta_onset_ms-1'] = df_80['delta_onset_ms'].shift(+1)\n",
    "df_80['delta_onset'] = df_80['t_dt_note_on'] - df_80['t_dt_note_on_ref']\n",
    "df_80['delta_onset-1'] = df_80['delta_onset'].shift(+1)\n",
    "df_80['prec_rest_ms'] = np.rint(df_80['prec_rest'] * (60 / df_80['bpm'] / 960)  * 1000)\n",
    "df_80['IOI_ms'] = np.rint(df_80['IOI'] * (60 / df_80['bpm'] / 960)  * 1000)\n",
    "df_80['PC-abs'] = df_80['PC'].abs()\n",
    "df_80['SC-abs'] = df_80['SC'].abs()\n",
    "df_80['velocity-1'] = df_80['velocity'].shift(+1)\n",
    "\n",
    "df_100['t_dt_note_on_ms'] = df_100['t_dt_note_on'] * (60 / df_100['bpm'] / 960) * 1000\n",
    "df_100['t_dt_note_off_ms'] = df_100['t_dt_note_off'] * (60 / df_100['bpm'] / 960)  * 1000\n",
    "df_100['delta_onset_ms'] = np.rint((df_100['t_dt_note_on'] - df_100['t_dt_note_on_ref']) * (60 / df_100['bpm'] / 960)  * 1000)\n",
    "df_100['delta_onset_ms-1'] = df_100['delta_onset_ms'].shift(+1)\n",
    "df_100['delta_onset'] = df_100['t_dt_note_on'] - df_100['t_dt_note_on_ref']\n",
    "df_100['delta_onset-1'] = df_100['delta_onset'].shift(+1)\n",
    "df_100['prec_rest_ms'] = np.rint(df_100['prec_rest'] * (60 / df_100['bpm'] / 960)  * 1000)\n",
    "df_100['IOI_ms'] = np.rint(df_100['IOI'] * (60 / df_100['bpm'] / 960)  * 1000)\n",
    "df_100['PC-abs'] = df_100['PC'].abs()\n",
    "df_100['SC-abs'] = df_100['SC'].abs()\n",
    "df_100['velocity-1'] = df_100['velocity'].shift(+1)\n",
    "\n",
    "df_120['t_dt_note_on_ms'] = df_120['t_dt_note_on'] * (60 / df_120['bpm'] / 960)  * 1000\n",
    "df_120['t_dt_note_off_ms'] = df_120['t_dt_note_off'] * (60 / df_120['bpm'] / 960)  * 1000\n",
    "df_120['delta_onset_ms'] = np.rint((df_120['t_dt_note_on'] - df_120['t_dt_note_on_ref']) * (60 / df_120['bpm'] / 960)  * 1000)\n",
    "df_120['delta_onset_ms-1'] = df_120['delta_onset_ms'].shift(+1)\n",
    "df_120['delta_onset'] = df_120['t_dt_note_on'] - df_120['t_dt_note_on_ref']\n",
    "df_120['delta_onset-1'] = df_120['delta_onset'].shift(+1)\n",
    "df_120['prec_rest_ms'] = np.rint(df_120['prec_rest'] * (60 / df_120['bpm'] / 960)  * 1000)\n",
    "df_120['IOI_ms'] = np.rint(df_120['IOI'] * (60 / df_120['bpm'] / 960)  * 1000)\n",
    "df_120['PC-abs'] = df_120['PC'].abs()\n",
    "df_120['SC-abs'] = df_120['SC'].abs()\n",
    "df_120['velocity-1'] = df_120['velocity'].shift(+1)\n",
    "\n",
    "# I remove the first note of each exercise because it has nan values for delta_onset-1, delta_onset_ms-1, velocity-1\n",
    "\n",
    "df_60 = df_60[df_60['ex_note_numb'] != 1]\n",
    "df_80 = df_80[df_80['ex_note_numb'] != 1]\n",
    "df_100 = df_100[df_100['ex_note_numb'] != 1]\n",
    "df_120 = df_120[df_120['ex_note_numb'] != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af8e73",
   "metadata": {},
   "source": [
    "## Onsets stats in MIDI ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_boxplot(data, color, pos=[0], ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    bp = ax.boxplot(data, patch_artist=False, positions=pos)\n",
    "    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']:\n",
    "        plt.setp(bp[item], color=color)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('Onsets deviations in MIDI ticks')\n",
    "bp_60 = color_boxplot(df_60['delta_onset'], 'green', [1])\n",
    "bp_80 = color_boxplot(df_80['delta_onset'], 'red', [2])\n",
    "bp_100 = color_boxplot(df_100['delta_onset'], 'purple', [3])\n",
    "bp_120 = color_boxplot(df_120['delta_onset'], 'blue', [4])\n",
    "ax.autoscale()\n",
    "ax.set(xticks=[1,2,3,4], xticklabels=['60 bpm','80 bpm','100 bpm','120 bpm'])\n",
    "plt.savefig('onset_stats_ticks_high_res.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "mean_df_60 = np.mean(df_60['delta_onset']) \n",
    "mean_df_80 = np.mean(df_80['delta_onset']) \n",
    "mean_df_100 = np.mean(df_100['delta_onset']) \n",
    "mean_df_120 = np.mean(df_120['delta_onset']) \n",
    "\n",
    "median_df_60 = np.median(df_60['delta_onset']) \n",
    "median_df_80 = np.median(df_80['delta_onset']) \n",
    "median_df_100 = np.median(df_100['delta_onset']) \n",
    "median_df_120 = np.median(df_120['delta_onset']) \n",
    "\n",
    "sd_df_60 = np.std(df_60['delta_onset']) \n",
    "sd_df_80 = np.std(df_80['delta_onset']) \n",
    "sd_df_100 = np.std(df_100['delta_onset']) \n",
    "sd_df_120 = np.std(df_120['delta_onset']) \n",
    "\n",
    "print(\"Mean at 60 bpm: \" + str(int(mean_df_60)) + \" ticks; Median: \" + str(int(median_df_60)) + \" ticks; Standard Deviation: \" + str(int(sd_df_60)) + \" ticks\") \n",
    "print(\"Mean at 80 bpm: \" + str(int(mean_df_80)) + \" ticks; Median: \" + str(int(median_df_80)) + \" ticks; Standard Deviation: \" + str(int(sd_df_80)) + \" ticks\") \n",
    "print(\"Mean at 100 bpm: \" + str(int(mean_df_100)) + \" ticks; Median: \" + str(int(median_df_100)) + \" ticks; Standard Deviation: \" + str(int(sd_df_100)) + \" ticks\") \n",
    "print(\"Mean at 100 bpm: \" + str(int(mean_df_120)) + \" ticks; Median: \" + str(int(median_df_120)) + \" ticks; Standard Deviation: \" + str(int(sd_df_120)) + \" ticks\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a4827",
   "metadata": {},
   "source": [
    "## Onsets stats in ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_boxplot(data, color, pos=[0], ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    bp = ax.boxplot(data, patch_artist=False, positions=pos)\n",
    "    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']:\n",
    "        plt.setp(bp[item], color=color)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('Onsets deviations in ms')\n",
    "bp_60 = color_boxplot(df_60[[\"delta_onset_ms\"]].to_numpy(), 'green', [1])\n",
    "bp_80 = color_boxplot(df_80[[\"delta_onset_ms\"]].to_numpy(), 'red', [2])\n",
    "bp_100 = color_boxplot(df_100[[\"delta_onset_ms\"]].to_numpy(), 'purple', [3])\n",
    "bp_120 = color_boxplot(df_120[[\"delta_onset_ms\"]].to_numpy(), 'blue', [4])\n",
    "ax.autoscale()\n",
    "ax.set(xticks=[1,2,3,4], xticklabels=['60 bpm','80 bpm','100 bpm','120 bpm'])\n",
    "plt.savefig('onset_stats_ms_high_res.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "mean_onsets_dev_60_ms = np.mean(df_60[[\"delta_onset_ms\"]].to_numpy()) \n",
    "mean_onsets_dev_80_ms = np.mean(df_80[[\"delta_onset_ms\"]].to_numpy()) \n",
    "mean_onsets_dev_100_ms = np.mean(df_100[[\"delta_onset_ms\"]].to_numpy()) \n",
    "mean_onsets_dev_120_ms = np.mean(df_120[[\"delta_onset_ms\"]].to_numpy()) \n",
    "\n",
    "median_onsets_dev_60_ms = np.median(df_60[[\"delta_onset_ms\"]].to_numpy()) \n",
    "median_onsets_dev_80_ms = np.median(df_80[[\"delta_onset_ms\"]].to_numpy()) \n",
    "median_onsets_dev_100_ms = np.median(df_100[[\"delta_onset_ms\"]].to_numpy()) \n",
    "median_onsets_dev_120_ms = np.median(df_120[[\"delta_onset_ms\"]].to_numpy()) \n",
    "\n",
    "sd_onsets_dev_60_ms = np.std(df_60[[\"delta_onset_ms\"]].to_numpy()) \n",
    "sd_onsets_dev_80_ms = np.std(df_80[[\"delta_onset_ms\"]].to_numpy()) \n",
    "sd_onsets_dev_100_ms = np.std(df_100[[\"delta_onset_ms\"]].to_numpy()) \n",
    "sd_onsets_dev_120_ms = np.std(df_120[[\"delta_onset_ms\"]].to_numpy()) \n",
    "\n",
    "print(\"Mean at 60 bpm: \" + str(int(mean_onsets_dev_60_ms)) + \" ms; Median: \" + str(int(median_onsets_dev_60_ms)) + \" ms; Standard Deviation: \" + str(int(sd_onsets_dev_60_ms)) + \" ms\") \n",
    "print(\"Mean at 80 bpm: \" + str(int(mean_onsets_dev_80_ms)) + \" ms; Median: \" + str(int(median_onsets_dev_80_ms)) + \" ms; Standard Deviation: \" + str(int(sd_onsets_dev_80_ms)) + \" ms\") \n",
    "print(\"Mean at 100 bpm: \" + str(int(mean_onsets_dev_100_ms)) + \" ms; Median: \" + str(int(median_onsets_dev_100_ms)) + \" ms; Standard Deviation: \" + str(int(sd_onsets_dev_100_ms)) + \" ms\") \n",
    "print(\"Mean at 100 bpm: \" + str(int(mean_onsets_dev_120_ms)) + \" ms; Median: \" + str(int(median_onsets_dev_120_ms)) + \" ms; Standard Deviation: \" + str(int(sd_onsets_dev_120_ms)) + \" ms\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac67ce6",
   "metadata": {},
   "source": [
    "## Concatenate df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776ea6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pd.concat([df_60, df_80, df_100, df_120], ignore_index=True)\n",
    "\n",
    "columns_order = [\n",
    "    'bpm', 'exercise', 'ex_note_numb', 'start-stop', 'note_numb',\n",
    "    'note_name', 'onbeat', 't_dt_note_on_ref', 't_dt_note_off_ref',\n",
    "    'note_lng_ref', 'IOI_ref', 'prec_rest_ref', 'string', 'fret', 'finger',\n",
    "    'position', 'PC', 'PC-abs', 'SC', 'SC-abs', 'HS', 'hammer-on', 'pull-off', \n",
    "    'bending', 'dt_note_on', 't_dt_note_on', 'dt_note_off', 't_dt_note_off',\n",
    "    'note_lng', 'IOI', 'prec_rest', 'fllw_rest', 'velocity', 'velocity-1',\n",
    "    't_dt_note_on_ms', 't_dt_note_off_ms', 'IOI_ms', 'prec_rest_ms', 'delta_onset',\n",
    "    'delta_onset-1','delta_onset_ms', 'delta_onset_ms-1'\n",
    "]\n",
    "\n",
    "df_complete = df_complete[columns_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc4506",
   "metadata": {},
   "source": [
    "## PC - Previous rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f93221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the groups of 'PC' values\n",
    "pc_groups = [\n",
    "    [-9, -8, -7, -6],   # Group 1\n",
    "    [-5, -4, -3],   # Group 2\n",
    "    [-2, -1],   # Group 3\n",
    "    [1, 2],      # Group 4\n",
    "    [3, 4, 5],      # Group 5\n",
    "    [6, 7, 8, 9]   # Group 6\n",
    "]\n",
    "\n",
    "# Create a list of labels for the groups\n",
    "group_labels = ['-9 to -6', '-5 to -3', '-2 to -1', '1 to 2', '3 to 5', '6 to 9']\n",
    "\n",
    "# Prepare data for boxplots and compute statistics for each group\n",
    "boxplot_data = []\n",
    "group_counts = []\n",
    "group_means = []\n",
    "group_medians = []\n",
    "group_stds = []\n",
    "\n",
    "for group in pc_groups:\n",
    "    group_data = df_complete[df_complete['PC'].isin(group)]['prec_rest_ms']\n",
    "    boxplot_data.append(group_data)\n",
    "    group_counts.append(len(group_data))\n",
    "    group_means.append(group_data.mean())\n",
    "    group_medians.append(group_data.median())\n",
    "    group_stds.append(group_data.std())\n",
    "\n",
    "# Display the count, mean, median, and standard deviation for each group\n",
    "\n",
    "\n",
    "for label, count, mean, median, std in zip(group_labels, group_counts, group_means, group_medians, group_stds):\n",
    "    print(f\"Group {label}:\")\n",
    "    print(f\"  Count: {count}\")\n",
    "    print(f\"  Mean: {mean:.2f}\")\n",
    "    print(f\"  Median: {median:.2f}\")\n",
    "    print(f\"  Standard Deviation: {std:.2f}\\n\")\n",
    "\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(boxplot_data, labels=group_labels)\n",
    "plt.xlabel('PC')\n",
    "plt.ylabel('prec_rest_ms')\n",
    "plt.ylim(0, 410)  # Limit y-axis to the range [0, 410]\n",
    "plt.grid(True)\n",
    "plt.savefig('prev_rest_PC_high_res.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d206bac7",
   "metadata": {},
   "source": [
    "## SC - Previous rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sc_values = sorted(df_complete['SC'].unique())\n",
    "unique_sc_values = [sc for sc in unique_sc_values if sc != 0]\n",
    "\n",
    "group_labels = [str(sc) for sc in unique_sc_values]\n",
    "\n",
    "boxplot_data = []\n",
    "group_counts = []\n",
    "group_means = []\n",
    "group_medians = []\n",
    "group_stds = []\n",
    "\n",
    "for sc in unique_sc_values:\n",
    "    group_data = df_complete[df_complete['SC'] == sc]['prec_rest_ms']\n",
    "    boxplot_data.append(group_data)\n",
    "    group_counts.append(len(group_data))\n",
    "    group_means.append(group_data.mean())\n",
    "    group_medians.append(group_data.median())\n",
    "    group_stds.append(group_data.std())\n",
    "\n",
    "# Display the count, mean, median, and standard deviation for each 'SC' value\n",
    "\n",
    "for label, count, mean, median, std in zip(group_labels, group_counts, group_means, group_medians, group_stds):\n",
    "    print(f\"SC {label}:\")\n",
    "    print(f\"  Count: {count}\")\n",
    "    print(f\"  Mean: {mean:.2f}\")\n",
    "    print(f\"  Median: {median:.2f}\")\n",
    "    print(f\"  Standard Deviation: {std:.2f}\\n\")\n",
    "\n",
    "# Boxplot generation\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(boxplot_data, labels=group_labels)\n",
    "plt.xlabel('SC')\n",
    "plt.ylabel('prec_rest_ms')\n",
    "plt.ylim(0, 310)\n",
    "plt.grid(True)\n",
    "plt.savefig('prev_rest_SC_high_res.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b70fddb",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929de515",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_corr = df_complete.drop(['bpm', 'exercise', 'ex_note_numb','start-stop', 'note_name','t_dt_note_on_ref','t_dt_note_off_ref','note_lng_ref','IOI_ref','prec_rest_ref','string','fret','finger','position','dt_note_on','t_dt_note_on','dt_note_off','t_dt_note_off','note_lng','IOI','prec_rest','fllw_rest','t_dt_note_on_ms','t_dt_note_off_ms', 'delta_onset', 'delta_onset-1'], axis=1)\n",
    "df_complete_dt_rf = df_complete.drop(['bpm', 'exercise', 'ex_note_numb','start-stop', 'note_name','t_dt_note_on_ref','t_dt_note_off_ref','note_lng_ref','IOI_ref','prec_rest_ref','string','fret','finger','position','dt_note_on','t_dt_note_on','dt_note_off','t_dt_note_off','note_lng','IOI','prec_rest','fllw_rest','t_dt_note_on_ms','t_dt_note_off_ms', 'delta_onset', 'delta_onset-1'], axis=1)\n",
    "df_complete_LSTM_RNN_ref = df_complete.drop(['bpm', 'exercise', 'start-stop', 'note_name','t_dt_note_on_ref','t_dt_note_off_ref','note_lng_ref','IOI_ref','prec_rest_ref','string','fret','finger','position','dt_note_on','t_dt_note_on','dt_note_off','t_dt_note_off','note_lng','IOI','prec_rest','fllw_rest','t_dt_note_on_ms','t_dt_note_off_ms', 'delta_onset', 'delta_onset-1'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9aff69",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "correlation_matrix = df_complete_corr.corr()\n",
    "\n",
    "# Heatmap generation\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt='.2f')\n",
    "plt.savefig('correlation_high_res.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ce87ff",
   "metadata": {},
   "source": [
    "## Decision tree onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd26f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decision_tree_onsets = df_complete_dt_rf.drop(['velocity', 'prec_rest_ms', 'PC-abs', 'SC-abs', 'IOI_ms'], axis=1)\n",
    "\n",
    "print(df_decision_tree_onsets.columns)\n",
    "\n",
    "# Features and target definition\n",
    "\n",
    "X = df_decision_tree_onsets.drop(columns=['delta_onset_ms'])\n",
    "y = df_decision_tree_onsets['delta_onset_ms']\n",
    "\n",
    "# Train-Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree Regressor\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=42, max_depth=10)  # Decision Tree model\n",
    "dt.fit(X_train, y_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "y_train_pred = dt.predict(X_train)\n",
    "\n",
    "# Evaluation of the model (test and training set)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test Mean Squared Error: {mse_test}\")\n",
    "print(f\"Test R-squared: {r2_test}\")\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "print(f\"Train Mean Squared Error: {mse_train}\")\n",
    "print(f\"Train R-squared: {r2_train}\")\n",
    "\n",
    "df_results_dt = pd.DataFrame({\n",
    "    'Real Values': y_test,\n",
    "    'Predicted Values': y_test_pred\n",
    "})\n",
    "\n",
    "df_results_dt['difference'] = df_results_dt['Real Values'] - df_results_dt['Predicted Values']\n",
    "\n",
    "# Plot the real and predicted values for the first 100 test samples\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "n_samples = 100\n",
    "plt.plot(y_test.values[:n_samples], label='Real Values', color='blue')\n",
    "plt.plot(y_test_pred[:n_samples], label='Predicted Values', color='red')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('delta_onset_ms')\n",
    "plt.ylim(-100, 100)\n",
    "plt.legend()\n",
    "plt.savefig('decision_tree_onsets_high_res.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e9367",
   "metadata": {},
   "source": [
    "## Random forest onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_forest_onsets = df_complete_dt_rf.drop(['velocity', 'prec_rest_ms', 'PC-abs', 'SC-abs', 'IOI_ms'], axis=1)\n",
    "print(df_random_forest_onsets.columns)\n",
    "\n",
    "# Features and target definition\n",
    "\n",
    "X = df_random_forest_onsets.drop(columns=['delta_onset_ms'])\n",
    "y = df_random_forest_onsets['delta_onset_ms']\n",
    "\n",
    "# Train-Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest Regressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, max_depth=10)  # Random Forest model\n",
    "rf.fit(X_train, y_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "# Evaluation of the model (test and training set)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test Mean Squared Error: {mse_test}\")\n",
    "print(f\"Test R-squared: {r2_test}\")\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "print(f\"Train Mean Squared Error: {mse_train}\")\n",
    "print(f\"Train R-squared: {r2_train}\")\n",
    "\n",
    "# Export regressor for offline use\n",
    "\n",
    "joblib.dump(rf, 'random_forest__regressor_onsets.pkl')\n",
    "\n",
    "df_results_rf = pd.DataFrame({\n",
    "    'Real Values': y_test,\n",
    "    'Predicted Values': y_test_pred\n",
    "})\n",
    "\n",
    "df_results_rf['difference'] = df_results_rf['Real Values'] - df_results_rf['Predicted Values']\n",
    "\n",
    "# Plot the real and predicted values for the first 100 test samples\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "n_samples = 100\n",
    "plt.plot(y_test.values[:n_samples], label='Real Values', color='blue')\n",
    "plt.plot(y_test_pred[:n_samples], label='Predicted Values', color='red')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('delta_onset_ms')\n",
    "plt.ylim(-100, 100)\n",
    "plt.legend()\n",
    "plt.savefig('random_forest_onsets_high_res.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7244db",
   "metadata": {},
   "source": [
    "## LSTM onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_LSTM_RNN = df_complete_LSTM_RNN_ref.copy()\n",
    "\n",
    "# Select features and target\n",
    "\n",
    "features = ['note_numb', 'onbeat', 'PC', 'SC', 'HS', 'hammer-on', 'pull-off', 'bending', 'delta_onset_ms-1', 'velocity-1']\n",
    "target = 'delta_onset_ms'\n",
    "\n",
    "X = df_complete_LSTM_RNN[features].values\n",
    "y = df_complete_LSTM_RNN[target].values\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Create sequences\n",
    "\n",
    "def create_sequences(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 1\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# Remove sequences containing rows where 'ex_note_numb' == 2\n",
    "\n",
    "indices_to_remove = df_complete_LSTM_RNN.index[df_complete_LSTM_RNN['ex_note_numb'] == 2].tolist()\n",
    "\n",
    "filtered_X_seq = []\n",
    "filtered_y_seq = []\n",
    "\n",
    "for i in range(len(X_seq)):\n",
    "    sequence_indices = list(range(i, i + time_steps + 1))\n",
    "    if not any(idx in indices_to_remove for idx in sequence_indices):\n",
    "        filtered_X_seq.append(X_seq[i])\n",
    "        filtered_y_seq.append(y_seq[i])  \n",
    "        \n",
    "filtered_X_seq = np.array(filtered_X_seq)\n",
    "filtered_y_seq = np.array(filtered_y_seq)\n",
    "\n",
    "if filtered_X_seq.size == 0:\n",
    "    print(\"No sequences remaining after filtering.\")\n",
    "else:\n",
    "    X_filtered = filtered_X_seq.reshape(filtered_X_seq.shape[0], time_steps, -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_y_seq, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # LSTM model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=40, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Add Early Stopping\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    epochs_used = len(history.epoch)\n",
    "    print(f\"Number of epochs used: {epochs_used}\")\n",
    "\n",
    "    # Test set predict\n",
    "    \n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))       \n",
    "\n",
    "    # Calculate MSE and R-squared on the test set\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Test): {mse_test}')\n",
    "    print(f'R-squared (Test): {r2_test}')\n",
    "\n",
    "    # Train set predict\n",
    "    \n",
    "    y_train_pred_scaled = model.predict(X_train)\n",
    "\n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_train = scaler_y.inverse_transform(y_train.reshape(-1, 1))                 \n",
    "\n",
    "    # Calculate MSE and R-squared on the training set\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f'Mean Squared Error (Training): {mse_train}')\n",
    "    print(f'R-squared (Training): {r2_train}')\n",
    "\n",
    "    # Plot the real and predicted values for the first 100 test samples\n",
    "    \n",
    "    window_size = 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test.flatten()[:window_size], label='Real Values', color='blue')\n",
    "    plt.plot(y_pred.flatten()[:window_size], label='Predicted Values', color='red')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('delta_onset_ms')\n",
    "    plt.ylim(-100, 100)\n",
    "    plt.legend()\n",
    "    plt.savefig('LSTM_onsets_high_res.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e62b53",
   "metadata": {},
   "source": [
    "## LSTM onsets 4 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeabc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_LSTM_RNN = df_complete_LSTM_RNN_ref.copy()\n",
    "\n",
    "# Select features and target\n",
    "\n",
    "features = ['ex_note_numb', 'note_numb', 'onbeat', 'PC', 'SC', 'HS', 'hammer-on', 'pull-off', 'bending', 'delta_onset_ms-1', 'velocity-1']\n",
    "target = 'delta_onset_ms'\n",
    "\n",
    "X = df_complete_LSTM_RNN[features].values\n",
    "y = df_complete_LSTM_RNN[target].values\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(df_complete_LSTM_RNN.drop(columns=['ex_note_numb'])[features[1:]].values)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Create sequences for the LSTM\n",
    "\n",
    "def create_sequences(X, y, time_steps=4):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 4\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# Remove sequences containing rows where 'ex_note_numb' == 2, 3, 4, or 5\n",
    "\n",
    "indices_to_remove = df_complete_LSTM_RNN.index[df_complete_LSTM_RNN['ex_note_numb'].isin([2, 3, 4, 5])].tolist()\n",
    "\n",
    "filtered_X_seq = []\n",
    "filtered_y_seq = []\n",
    "\n",
    "for i in range(len(X_seq)):\n",
    "    sequence_indices = list(range(i, i + time_steps + 1))\n",
    "    if not any(idx in indices_to_remove for idx in sequence_indices):\n",
    "        filtered_X_seq.append(X_seq[i])\n",
    "        filtered_y_seq.append(y_seq[i])  \n",
    "\n",
    "filtered_X_seq = np.array(filtered_X_seq)\n",
    "filtered_y_seq = np.array(filtered_y_seq)\n",
    "\n",
    "if filtered_X_seq.size == 0:\n",
    "    print(\"No sequences remaining after filtering.\")\n",
    "else:\n",
    "    X_filtered = filtered_X_seq.reshape(filtered_X_seq.shape[0], time_steps, -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_y_seq, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # LSTM model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=40, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Add Early Stopping\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    epochs_used = len(history.epoch)\n",
    "    print(f\"Number of epochs used: {epochs_used}\")\n",
    "\n",
    "    # Test set predict\n",
    "    \n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))       \n",
    "\n",
    "    # Calculate MSE and R-squared on the test set\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Test): {mse_test}')\n",
    "    print(f'R-squared (Test): {r2_test}')\n",
    "\n",
    "    # Train set predict\n",
    "    \n",
    "    y_train_pred_scaled = model.predict(X_train)\n",
    "\n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_train = scaler_y.inverse_transform(y_train.reshape(-1, 1))                 \n",
    "\n",
    "    # Calculate MSE and R-squared on the training set\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f'Mean Squared Error (Training): {mse_train}')\n",
    "    print(f'R-squared (Training): {r2_train}')\n",
    "\n",
    "    # Plot the real and predicted values for the first 100 test samples\n",
    "    \n",
    "    window_size = 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test.flatten()[:window_size], label='Real Values', color='blue')\n",
    "    plt.plot(y_pred.flatten()[:window_size], label='Predicted Values', color='red')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('delta_onset_ms')\n",
    "    plt.ylim(-100, 100)\n",
    "    plt.legend()\n",
    "    plt.savefig('LSTM-4_onsets_high_res.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2710e",
   "metadata": {},
   "source": [
    "## RNN onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c50c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_LSTM_RNN = df_complete_LSTM_RNN_ref.copy()\n",
    "\n",
    "# Select features and target\n",
    "features = ['note_numb', 'onbeat', 'PC', 'SC', 'HS', 'hammer-on', 'pull-off', 'bending', 'delta_onset_ms-1', 'velocity-1']\n",
    "target = 'delta_onset_ms'\n",
    "\n",
    "X = df_complete_LSTM_RNN[features].values\n",
    "y = df_complete_LSTM_RNN[target].values\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Create sequences\n",
    "\n",
    "def create_sequences(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 1\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# Remove sequences containing rows where 'ex_note_numb' == 2\n",
    "\n",
    "indices_to_remove = df_complete_LSTM_RNN.index[df_complete_LSTM_RNN['ex_note_numb'] == 2].tolist()\n",
    "\n",
    "filtered_X_seq = []\n",
    "filtered_y_seq = []\n",
    "\n",
    "for i in range(len(X_seq)):\n",
    "    sequence_indices = list(range(i, i + time_steps + 1))\n",
    "    if not any(idx in indices_to_remove for idx in sequence_indices):\n",
    "        filtered_X_seq.append(X_seq[i])\n",
    "        filtered_y_seq.append(y_seq[i])  \n",
    "        \n",
    "filtered_X_seq = np.array(filtered_X_seq)\n",
    "filtered_y_seq = np.array(filtered_y_seq)\n",
    "\n",
    "if filtered_X_seq.size == 0:\n",
    "    print(\"No sequences remaining after filtering.\")\n",
    "else:\n",
    "    X_filtered = filtered_X_seq.reshape(filtered_X_seq.shape[0], time_steps, -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_y_seq, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # RNN model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=40, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Add Early Stopping\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    epochs_used = len(history.epoch)\n",
    "    print(f\"Number of epochs used: {epochs_used}\")\n",
    "\n",
    "    # Test set predict\n",
    "    \n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))       \n",
    "\n",
    "    # Calculate MSE and R-squared on the test set\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Test): {mse_test}')\n",
    "    print(f'R-squared (Test): {r2_test}')\n",
    "\n",
    "    # Train set predict\n",
    "    \n",
    "    y_train_pred_scaled = model.predict(X_train)\n",
    "\n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_train = scaler_y.inverse_transform(y_train.reshape(-1, 1))                 \n",
    "\n",
    "    # Calculate MSE and R-squared on the training set\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f'Mean Squared Error (Training): {mse_train}')\n",
    "    print(f'R-squared (Training): {r2_train}')\n",
    "\n",
    "    # Plot the real and predicted values for the first 100 test samples\n",
    "    \n",
    "    window_size = 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test.flatten()[:window_size], label='Real Values', color='blue')\n",
    "    plt.plot(y_pred.flatten()[:window_size], label='Predicted Values', color='red')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('delta_onset_ms')\n",
    "    plt.ylim(-100, 100)\n",
    "    plt.legend()\n",
    "    plt.savefig('RNN_onsets_high_res.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50f891",
   "metadata": {},
   "source": [
    "## RNN onsets 4 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e612acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_LSTM_RNN = df_complete_LSTM_RNN_ref.copy()\n",
    "\n",
    "# Select features and target\n",
    "\n",
    "features = ['note_numb', 'onbeat', 'PC', 'SC', 'HS', 'hammer-on', 'pull-off', 'bending', 'delta_onset_ms-1', 'velocity-1']\n",
    "target = 'delta_onset_ms'\n",
    "\n",
    "X = df_complete_LSTM_RNN[features].values  # Removed 'ex_note_numb' here\n",
    "y = df_complete_LSTM_RNN[target].values\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Create sequences\n",
    "\n",
    "def create_sequences(X, y, time_steps=4):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 4\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# Remove sequences containing rows where 'ex_note_numb' == 2, 3, 4, or 5\n",
    "\n",
    "indices_to_remove = df_complete_LSTM_RNN.index[df_complete_LSTM_RNN['ex_note_numb'].isin([2, 3, 4, 5])].tolist()\n",
    "\n",
    "filtered_X_seq = []\n",
    "filtered_y_seq = []\n",
    "\n",
    "for i in range(len(X_seq)):\n",
    "    sequence_indices = list(range(i, i + time_steps + 1))\n",
    "    if not any(idx in indices_to_remove for idx in sequence_indices):\n",
    "        filtered_X_seq.append(X_seq[i])\n",
    "        filtered_y_seq.append(y_seq[i])  \n",
    "        \n",
    "filtered_X_seq = np.array(filtered_X_seq)\n",
    "filtered_y_seq = np.array(filtered_y_seq)\n",
    "\n",
    "if filtered_X_seq.size == 0:\n",
    "    print(\"No sequences remaining after filtering.\")\n",
    "else:\n",
    "    X_filtered = filtered_X_seq.reshape(filtered_X_seq.shape[0], time_steps, -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_y_seq, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # RNN model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=40, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Add Early Stopping\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "    \n",
    "    epochs_used = len(history.epoch)\n",
    "    print(f\"Number of epochs used: {epochs_used}\")\n",
    "\n",
    "    # Test set predict\n",
    "    \n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "    \n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))       \n",
    "\n",
    "    # Calculate MSE and R-squared on the test set\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Test): {mse_test}')\n",
    "    print(f'R-squared (Test): {r2_test}')\n",
    "\n",
    "    # Train set predict\n",
    "    \n",
    "    y_train_pred_scaled = model.predict(X_train)\n",
    "    \n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_train = scaler_y.inverse_transform(y_train.reshape(-1, 1))                 \n",
    "\n",
    "    # Calculate MSE and R-squared on the training set\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f'Mean Squared Error (Training): {mse_train}')\n",
    "    print(f'R-squared (Training): {r2_train}')\n",
    "\n",
    "    # Plot the real and predicted values for the first 100 test samples\n",
    "    \n",
    "    window_size = 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test.flatten()[:window_size], label='Real Values', color='blue')\n",
    "    plt.plot(y_pred.flatten()[:window_size], label='Predicted Values', color='red')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('delta_onset_ms')\n",
    "    plt.ylim(-100, 100)\n",
    "    plt.legend()\n",
    "    plt.savefig('RNN-4_onsets_high_res.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93143f5",
   "metadata": {},
   "source": [
    "## Decision tree prec rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decision_tree_prec_rest = df_complete_dt_rf.drop(['velocity', 'delta_onset_ms', 'PC-abs', 'SC-abs', 'IOI_ms'], axis=1)\n",
    "print(df_decision_tree_prec_rest.columns)\n",
    "\n",
    "# Features and target definition\n",
    "\n",
    "X = df_decision_tree_prec_rest.drop(columns=['prec_rest_ms'])\n",
    "y = df_decision_tree_prec_rest['prec_rest_ms']\n",
    "\n",
    "# Train-Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree Regressor\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=42, max_depth=10)  # Decision Tree model\n",
    "dt.fit(X_train, y_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "y_train_pred = dt.predict(X_train)\n",
    "\n",
    "# Evaluation of the model (test and training set)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test Mean Squared Error: {mse_test}\")\n",
    "print(f\"Test R-squared: {r2_test}\")\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "print(f\"Train Mean Squared Error: {mse_train}\")\n",
    "print(f\"Train R-squared: {r2_train}\")\n",
    "\n",
    "df_results_dt = pd.DataFrame({\n",
    "    'Real Values': y_test,\n",
    "    'Predicted Values': y_test_pred\n",
    "})\n",
    "\n",
    "df_results_dt['difference'] = df_results_dt['Real Values'] - df_results_dt['Predicted Values']\n",
    "\n",
    "# Plot the real and predicted values for the first 100 test samples\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "window_size = 100\n",
    "plt.plot(y_test.values[0:window_size], label='Real Values', color='blue')\n",
    "plt.plot(y_test_pred[0:window_size], label='Predicted Values', color='red')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('prec_rest_ms')\n",
    "plt.ylim(0, 250)\n",
    "plt.legend()\n",
    "plt.savefig('decision_tree_prec_rest_high_res.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b0955f",
   "metadata": {},
   "source": [
    "## Random forest prec_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_forest_prec_rest = df_complete_dt_rf.drop(['velocity', 'delta_onset_ms', 'PC-abs', 'SC-abs', 'IOI_ms'], axis=1)\n",
    "print(df_random_forest_prec_rest.columns)\n",
    "\n",
    "# Features and target definition\n",
    "\n",
    "X = df_random_forest_prec_rest.drop(columns=['prec_rest_ms'])\n",
    "y = df_random_forest_prec_rest['prec_rest_ms']\n",
    "\n",
    "# Train-Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest Regressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, max_depth=10)  # Random Forest model\n",
    "rf.fit(X_train, y_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "# Evaluation of the model (test and training set)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test Mean Squared Error: {mse_test}\")\n",
    "print(f\"Test R-squared: {r2_test}\")\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "print(f\"Train Mean Squared Error: {mse_train}\")\n",
    "print(f\"Train R-squared: {r2_train}\")\n",
    "\n",
    "df_results_rf = pd.DataFrame({\n",
    "    'Real Values': y_test,\n",
    "    'Predicted Values': y_test_pred\n",
    "})\n",
    "\n",
    "df_results_rf['difference'] = df_results_rf['Real Values'] - df_results_rf['Predicted Values']\n",
    "\n",
    "# Plot the real and predicted values for the first 100 test samples\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "window_size = 100\n",
    "plt.plot(y_test.values[0:window_size], label='Real Values', color='blue')\n",
    "plt.plot(y_test_pred[0:window_size], label='Predicted Values', color='red')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('prec_rest_ms')\n",
    "plt.ylim(0, 250)\n",
    "plt.legend()\n",
    "plt.savefig('random_forest_prec_rest_high_res.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5512658",
   "metadata": {},
   "source": [
    "## LSTM prec_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f86a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_LSTM_RNN = df_complete_LSTM_RNN_ref.copy()\n",
    "\n",
    "# Select features and target\n",
    "\n",
    "features = ['note_numb', 'onbeat', 'PC', 'SC', 'HS', 'hammer-on', 'pull-off', 'bending', 'delta_onset_ms-1', 'velocity-1']\n",
    "target = 'prec_rest_ms'\n",
    "\n",
    "X = df_complete_LSTM_RNN[features].values\n",
    "y = df_complete_LSTM_RNN[target].values\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Create sequences\n",
    "\n",
    "def create_sequences(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 1\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# Remove sequences containing rows where 'ex_note_numb' == 2\n",
    "\n",
    "indices_to_remove = df_complete_LSTM_RNN.index[df_complete_LSTM_RNN['ex_note_numb'] == 2].tolist()\n",
    "\n",
    "filtered_X_seq = []\n",
    "filtered_y_seq = []\n",
    "\n",
    "for i in range(len(X_seq)):\n",
    "    sequence_indices = list(range(i, i + time_steps + 1))\n",
    "    if not any(idx in indices_to_remove for idx in sequence_indices):\n",
    "        filtered_X_seq.append(X_seq[i])\n",
    "        filtered_y_seq.append(y_seq[i])  \n",
    "        \n",
    "filtered_X_seq = np.array(filtered_X_seq)\n",
    "filtered_y_seq = np.array(filtered_y_seq)\n",
    "\n",
    "if filtered_X_seq.size == 0:\n",
    "    print(\"No sequences remaining after filtering.\")\n",
    "else:\n",
    "    X_filtered = filtered_X_seq.reshape(filtered_X_seq.shape[0], time_steps, -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_y_seq, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # LSTM model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=40, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Add Early Stopping\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    epochs_used = len(history.epoch)\n",
    "    print(f\"Number of epochs used: {epochs_used}\")\n",
    "\n",
    "    # Test set predict\n",
    "    \n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))       \n",
    "\n",
    "    # Calculate MSE and R-squared on the test set\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Test): {mse_test}')\n",
    "    print(f'R-squared (Test): {r2_test}')\n",
    "\n",
    "    # Train set predict\n",
    "    \n",
    "    y_train_pred_scaled = model.predict(X_train)\n",
    "\n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_train = scaler_y.inverse_transform(y_train.reshape(-1, 1))                 \n",
    "\n",
    "    # Calculate MSE and R-squared on the training set\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f'Mean Squared Error (Training): {mse_train}')\n",
    "    print(f'R-squared (Training): {r2_train}')\n",
    "\n",
    "    # Plot the real and predicted values for the first 100 test samples\n",
    "    \n",
    "    window_size = 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test.flatten()[0:window_size], label='Real Values', color='blue')\n",
    "    plt.plot(y_pred.flatten()[0:window_size], label='Predicted Values', color='red')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('prec_rest_ms')\n",
    "    plt.ylim(0, 250)\n",
    "    plt.legend()\n",
    "    plt.savefig('LSTM_prec_rest_high_res.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1285bc7",
   "metadata": {},
   "source": [
    "## LSTM prec_rest 4 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d90626",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_LSTM_RNN = df_complete_LSTM_RNN_ref.copy()\n",
    "\n",
    "# Select features and target\n",
    "\n",
    "features = ['ex_note_numb', 'note_numb', 'onbeat', 'PC', 'SC', 'HS', 'hammer-on', 'pull-off', 'bending', 'delta_onset_ms-1', 'velocity-1']\n",
    "target = 'prec_rest_ms'\n",
    "\n",
    "X = df_complete_LSTM_RNN[features].values\n",
    "y = df_complete_LSTM_RNN[target].values\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(df_complete_LSTM_RNN.drop(columns=['ex_note_numb'])[features[1:]].values)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Create sequences\n",
    "\n",
    "def create_sequences(X, y, time_steps=4):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 4\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# Remove sequences containing rows where 'ex_note_numb' == 2, 3, 4, or 5\n",
    "\n",
    "indices_to_remove = df_complete_LSTM_RNN.index[df_complete_LSTM_RNN['ex_note_numb'].isin([2, 3, 4, 5])].tolist()\n",
    "\n",
    "filtered_X_seq = []\n",
    "filtered_y_seq = []\n",
    "\n",
    "for i in range(len(X_seq)):\n",
    "    sequence_indices = list(range(i, i + time_steps + 1))\n",
    "    if not any(idx in indices_to_remove for idx in sequence_indices):\n",
    "        filtered_X_seq.append(X_seq[i])\n",
    "        filtered_y_seq.append(y_seq[i])  \n",
    "\n",
    "filtered_X_seq = np.array(filtered_X_seq)\n",
    "filtered_y_seq = np.array(filtered_y_seq)\n",
    "\n",
    "if filtered_X_seq.size == 0:\n",
    "    print(\"No sequences remaining after filtering.\")\n",
    "else:\n",
    "    X_filtered = filtered_X_seq.reshape(filtered_X_seq.shape[0], time_steps, -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_y_seq, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # LSTM model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=40, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Add Early Stopping\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    epochs_used = len(history.epoch)\n",
    "    print(f\"Number of epochs used: {epochs_used}\")\n",
    "\n",
    "    # Test set predict\n",
    "    \n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))       \n",
    "\n",
    "    # Calculate MSE and R-squared on the test set\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Test): {mse_test}')\n",
    "    print(f'R-squared (Test): {r2_test}')\n",
    "\n",
    "    # Train set predict\n",
    "    \n",
    "    y_train_pred_scaled = model.predict(X_train)\n",
    "\n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_train = scaler_y.inverse_transform(y_train.reshape(-1, 1))                 \n",
    "\n",
    "    # Calculate MSE and R-squared on the training set\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f'Mean Squared Error (Training): {mse_train}')\n",
    "    print(f'R-squared (Training): {r2_train}')\n",
    "\n",
    "    # Plot the real and predicted values for the first 100 test samples\n",
    "    \n",
    "    window_size = 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test.flatten()[0:window_size], label='Real Values', color='blue')\n",
    "    plt.plot(y_pred.flatten()[0:window_size], label='Predicted Values', color='red')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('prec_rest_ms')\n",
    "    plt.ylim(0, 250)\n",
    "    plt.legend()\n",
    "    plt.savefig('LSTM-4_prec_rest_high_res.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f09fefd",
   "metadata": {},
   "source": [
    "## RNN prec_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8121183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_LSTM_RNN = df_complete_LSTM_RNN_ref.copy()\n",
    "\n",
    "# Select features and target\n",
    "\n",
    "features = ['note_numb', 'onbeat', 'PC', 'SC', 'HS', 'hammer-on', 'pull-off', 'bending', 'delta_onset_ms-1', 'velocity-1']\n",
    "target = 'prec_rest_ms'\n",
    "\n",
    "X = df_complete_LSTM_RNN[features].values\n",
    "y = df_complete_LSTM_RNN[target].values\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Create sequences\n",
    "\n",
    "def create_sequences(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 1\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# Remove sequences containing rows where 'ex_note_numb' == 2\n",
    "\n",
    "indices_to_remove = df_complete_LSTM_RNN.index[df_complete_LSTM_RNN['ex_note_numb'] == 2].tolist()\n",
    "\n",
    "filtered_X_seq = []\n",
    "filtered_y_seq = []\n",
    "\n",
    "for i in range(len(X_seq)):\n",
    "    sequence_indices = list(range(i, i + time_steps + 1))\n",
    "    if not any(idx in indices_to_remove for idx in sequence_indices):\n",
    "        filtered_X_seq.append(X_seq[i])\n",
    "        filtered_y_seq.append(y_seq[i])  \n",
    "        \n",
    "filtered_X_seq = np.array(filtered_X_seq)\n",
    "filtered_y_seq = np.array(filtered_y_seq)\n",
    "\n",
    "if filtered_X_seq.size == 0:\n",
    "    print(\"No sequences remaining after filtering.\")\n",
    "else:\n",
    "    X_filtered = filtered_X_seq.reshape(filtered_X_seq.shape[0], time_steps, -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_y_seq, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # RNN model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=40, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Add Early Stopping\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    epochs_used = len(history.epoch)\n",
    "    print(f\"Number of epochs used: {epochs_used}\")\n",
    "\n",
    "    # Test set predict\n",
    "    \n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))       \n",
    "\n",
    "    # Calculate MSE and R-squared on the test set\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Test): {mse_test}')\n",
    "    print(f'R-squared (Test): {r2_test}')\n",
    "\n",
    "    # Train set predict\n",
    "    \n",
    "    y_train_pred_scaled = model.predict(X_train)\n",
    "\n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_train = scaler_y.inverse_transform(y_train.reshape(-1, 1))                 \n",
    "\n",
    "    # Calculate MSE and R-squared on the training set\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f'Mean Squared Error (Training): {mse_train}')\n",
    "    print(f'R-squared (Training): {r2_train}')\n",
    "\n",
    "    # Plot the real and predicted values for the first 100 test samples\n",
    "    \n",
    "    window_size = 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test.flatten()[0:window_size], label='Real Values', color='blue')\n",
    "    plt.plot(y_pred.flatten()[0:window_size], label='Predicted Values', color='red')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('prec_rest_ms')\n",
    "    plt.ylim(0, 250)\n",
    "    plt.legend()\n",
    "    plt.savefig('RNN_prec_rest_high_res.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f9c95",
   "metadata": {},
   "source": [
    "## RNN prec_rest 4 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300b534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_LSTM_RNN = df_complete_LSTM_RNN_ref.copy()\n",
    "\n",
    "# Select features and target \n",
    "\n",
    "features = ['note_numb', 'onbeat', 'PC', 'SC', 'HS', 'hammer-on', 'pull-off', 'bending', 'delta_onset_ms-1', 'velocity-1']\n",
    "target = 'prec_rest_ms'\n",
    "\n",
    "X = df_complete_LSTM_RNN[features].values  # Removed 'ex_note_numb' here\n",
    "y = df_complete_LSTM_RNN[target].values\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Save the scalers to disk\n",
    "\n",
    "joblib.dump(scaler_X, 'scaler_X_prec_rest.pkl')\n",
    "joblib.dump(scaler_y, 'scaler_y_prec_rest.pkl')\n",
    "\n",
    "# Create sequences\n",
    "\n",
    "def create_sequences(X, y, time_steps=4):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 4\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# Remove sequences containing rows where 'ex_note_numb' == 2, 3, 4, or 5\n",
    "\n",
    "indices_to_remove = df_complete_LSTM_RNN.index[df_complete_LSTM_RNN['ex_note_numb'].isin([2, 3, 4, 5])].tolist()\n",
    "\n",
    "filtered_X_seq = []\n",
    "filtered_y_seq = []\n",
    "\n",
    "for i in range(len(X_seq)):\n",
    "    sequence_indices = list(range(i, i + time_steps + 1))\n",
    "    if not any(idx in indices_to_remove for idx in sequence_indices):\n",
    "        filtered_X_seq.append(X_seq[i])\n",
    "        filtered_y_seq.append(y_seq[i])  \n",
    "        \n",
    "filtered_X_seq = np.array(filtered_X_seq)\n",
    "filtered_y_seq = np.array(filtered_y_seq)\n",
    "\n",
    "if filtered_X_seq.size == 0:\n",
    "    print(\"No sequences remaining after filtering.\")\n",
    "else:\n",
    "    X_filtered = filtered_X_seq.reshape(filtered_X_seq.shape[0], time_steps, -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_y_seq, test_size=0.2, random_state=42, shuffle=True)\n",
    "    \n",
    "    # RNN model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=40, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Add Early Stopping\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "    \n",
    "    epochs_used = len(history.epoch)\n",
    "    print(f\"Number of epochs used: {epochs_used}\")\n",
    "\n",
    "    # Test set predict\n",
    "    \n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "    \n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))       \n",
    "\n",
    "    # Calculate MSE and R-squared on the test set\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Test): {mse_test}')\n",
    "    print(f'R-squared (Test): {r2_test}')\n",
    "\n",
    "    # Train set predict\n",
    "    \n",
    "    y_train_pred_scaled = model.predict(X_train)\n",
    "    \n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_train = scaler_y.inverse_transform(y_train.reshape(-1, 1))                 \n",
    "\n",
    "    # Calculate MSE and R-squared on the training set\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f'Mean Squared Error (Training): {mse_train}')\n",
    "    print(f'R-squared (Training): {r2_train}')\n",
    "\n",
    "    # Export regressor for offline use\n",
    "    \n",
    "    model.save('RNN-4_regressor_prec_rests.h5')\n",
    "    \n",
    "    # Plot the real and predicted values for the first 100 test samples\n",
    "    \n",
    "    window_size = 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test.flatten()[0:window_size], label='Real Values', color='blue')\n",
    "    plt.plot(y_pred.flatten()[0:window_size], label='Predicted Values', color='red')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('delta_onset_ms')\n",
    "    plt.ylim(0, 250)\n",
    "    plt.legend()\n",
    "    plt.savefig('RNN-4_prec_rest_high_res.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23f102",
   "metadata": {},
   "source": [
    "## Decision tree velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f32ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decision_tree_velocity = df_complete_dt_rf.drop(['prec_rest_ms', 'delta_onset_ms', 'PC-abs', 'SC-abs', 'IOI_ms'], axis=1)\n",
    "print(df_decision_tree_velocity.columns)\n",
    "\n",
    "# Features and target definition\n",
    "\n",
    "X = df_decision_tree_velocity.drop(columns=['velocity'])\n",
    "y = df_decision_tree_velocity['velocity']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor(random_state=42, max_depth=10)  # Decision Tree model\n",
    "dt.fit(X_train, y_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "y_train_pred = dt.predict(X_train)\n",
    "\n",
    "# Evaluation of the model (test and training set)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test Mean Squared Error: {mse_test}\")\n",
    "print(f\"Test R-squared: {r2_test}\")\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "print(f\"Train Mean Squared Error: {mse_train}\")\n",
    "print(f\"Train R-squared: {r2_train}\")\n",
    "\n",
    "df_results_dt = pd.DataFrame({\n",
    "    'Real Values': y_test,\n",
    "    'Predicted Values': y_test_pred\n",
    "})\n",
    "\n",
    "df_results_dt['difference'] = df_results_dt['Real Values'] - df_results_dt['Predicted Values']\n",
    "\n",
    "# Plot the real and predicted values for the first 100 test samples\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "n_samples = 100\n",
    "plt.plot(y_test.values[:n_samples], label='Real Values', color='blue')\n",
    "plt.plot(y_test_pred[:n_samples], label='Predicted Values', color='red')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('velocity')\n",
    "plt.ylim(0, 127)\n",
    "plt.legend()\n",
    "plt.savefig('decision_tree_velocity_high_res.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9eef5",
   "metadata": {},
   "source": [
    "## Random forest velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7912ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_forest_velocity = df_complete_dt_rf.drop(['prec_rest_ms', 'delta_onset_ms', 'PC-abs', 'SC-abs', 'IOI_ms'], axis=1)\n",
    "print(df_random_forest_velocity.columns)\n",
    "\n",
    "# Features and target definition\n",
    "\n",
    "X = df_random_forest_velocity.drop(columns=['velocity'])\n",
    "y = df_random_forest_velocity['velocity']\n",
    "\n",
    "# Train-Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest Regressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, max_depth=10)  # Random Forest model\n",
    "rf.fit(X_train, y_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "# Evaluation of the model (test and training set)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test Mean Squared Error: {mse_test}\")\n",
    "print(f\"Test R-squared: {r2_test}\")\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "print(f\"Train Mean Squared Error: {mse_train}\")\n",
    "print(f\"Train R-squared: {r2_train}\")\n",
    "\n",
    "df_results_rf = pd.DataFrame({\n",
    "    'Real Values': y_test,\n",
    "    'Predicted Values': y_test_pred\n",
    "})\n",
    "\n",
    "df_results_rf['difference'] = df_results_rf['Real Values'] - df_results_rf['Predicted Values']\n",
    "\n",
    "# Plot the real and predicted values for the first 100 test samples\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "n_samples = 100\n",
    "plt.plot(y_test.values[:n_samples], label='Real Values', color='blue')\n",
    "plt.plot(y_test_pred[:n_samples], label='Predicted Values', color='red')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('velocity')\n",
    "plt.ylim(0, 127)\n",
    "plt.legend()\n",
    "plt.savefig('random_forest_velocity_high_res.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c48d2c",
   "metadata": {},
   "source": [
    "## LSTM velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8911a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_LSTM_RNN = df_complete_LSTM_RNN_ref.copy()\n",
    "\n",
    "# Select features and target\n",
    "\n",
    "features = ['note_numb', 'onbeat', 'PC', 'SC', 'HS', 'hammer-on', 'pull-off', 'bending', 'delta_onset_ms-1', 'velocity-1']\n",
    "target = 'velocity'\n",
    "\n",
    "X = df_complete_LSTM_RNN[features].values\n",
    "y = df_complete_LSTM_RNN[target].values\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Create sequences \n",
    "\n",
    "def create_sequences(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 1\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# Remove sequences containing rows where 'ex_note_numb' == 2\n",
    "\n",
    "indices_to_remove = df_complete_LSTM_RNN.index[df_complete_LSTM_RNN['ex_note_numb'] == 2].tolist()\n",
    "\n",
    "filtered_X_seq = []\n",
    "filtered_y_seq = []\n",
    "\n",
    "for i in range(len(X_seq)):\n",
    "    sequence_indices = list(range(i, i + time_steps + 1))\n",
    "    if not any(idx in indices_to_remove for idx in sequence_indices):\n",
    "        filtered_X_seq.append(X_seq[i])\n",
    "        filtered_y_seq.append(y_seq[i])  \n",
    "        \n",
    "filtered_X_seq = np.array(filtered_X_seq)\n",
    "filtered_y_seq = np.array(filtered_y_seq)\n",
    "\n",
    "if filtered_X_seq.size == 0:\n",
    "    print(\"No sequences remaining after filtering.\")\n",
    "else:\n",
    "    X_filtered = filtered_X_seq.reshape(filtered_X_seq.shape[0], time_steps, -1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_y_seq, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # LSTM model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=40, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Add Early Stopping\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    epochs_used = len(history.epoch)\n",
    "    print(f\"Number of epochs used: {epochs_used}\")\n",
    "\n",
    "    # Test set predict\n",
    "    \n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))       \n",
    "\n",
    "    # Calculate MSE and R-squared on the test set\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Test): {mse_test}')\n",
    "    print(f'R-squared (Test): {r2_test}')\n",
    "\n",
    "    # Train set predict\n",
    "    \n",
    "    y_train_pred_scaled = model.predict(X_train)\n",
    "\n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_train = scaler_y.inverse_transform(y_train.reshape(-1, 1))                 \n",
    "\n",
    "    # Calculate MSE and R-squared on the training set\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f'Mean Squared Error (Training): {mse_train}')\n",
    "    print(f'R-squared (Training): {r2_train}')\n",
    "\n",
    "    # Plot the real and predicted values for the first 100 test samples\n",
    "    \n",
    "    window_size = 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test.flatten()[:window_size], label='Real Values', color='blue')\n",
    "    plt.plot(y_pred.flatten()[:window_size], label='Predicted Values', color='red')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('velocity')\n",
    "    plt.ylim(0, 127)\n",
    "    plt.legend()\n",
    "    plt.savefig('LSTM_velocity_high_res.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb821a",
   "metadata": {},
   "source": [
    "## LSTM velocity 4 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625afb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_LSTM_RNN = df_complete_LSTM_RNN_ref.copy()\n",
    "\n",
    "# Select features and target\n",
    "\n",
    "features = ['ex_note_numb', 'note_numb', 'onbeat', 'PC', 'SC', 'HS', 'hammer-on', 'pull-off', 'bending', 'delta_onset_ms-1', 'velocity-1']\n",
    "target = 'velocity'\n",
    "\n",
    "X = df_complete_LSTM_RNN[features].values\n",
    "y = df_complete_LSTM_RNN[target].values\n",
    "\n",
    "# Data normalization \n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(df_complete_LSTM_RNN.drop(columns=['ex_note_numb'])[features[1:]].values)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Create sequences\n",
    "\n",
    "def create_sequences(X, y, time_steps=4):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 4\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# Remove sequences containing rows where 'ex_note_numb' == 2, 3, 4, or 5\n",
    "\n",
    "indices_to_remove = df_complete_LSTM_RNN.index[df_complete_LSTM_RNN['ex_note_numb'].isin([2, 3, 4, 5])].tolist()\n",
    "\n",
    "filtered_X_seq = []\n",
    "filtered_y_seq = []\n",
    "\n",
    "for i in range(len(X_seq)):\n",
    "    sequence_indices = list(range(i, i + time_steps + 1))\n",
    "    if not any(idx in indices_to_remove for idx in sequence_indices):\n",
    "        filtered_X_seq.append(X_seq[i])\n",
    "        filtered_y_seq.append(y_seq[i])  \n",
    "        \n",
    "filtered_X_seq = np.array(filtered_X_seq)\n",
    "filtered_y_seq = np.array(filtered_y_seq)\n",
    "\n",
    "if filtered_X_seq.size == 0:\n",
    "    print(\"No sequences remaining after filtering.\")\n",
    "else:\n",
    "    X_filtered = filtered_X_seq.reshape(filtered_X_seq.shape[0], time_steps, -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_y_seq, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # LSTM model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=40, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Add Early Stopping\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    epochs_used = len(history.epoch)\n",
    "    print(f\"Number of epochs used: {epochs_used}\")\n",
    "\n",
    "    # Test set predict\n",
    "    \n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))       \n",
    "\n",
    "    # Calculate MSE and R-squared on the test set\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Test): {mse_test}')\n",
    "    print(f'R-squared (Test): {r2_test}')\n",
    "\n",
    "    # Train set predict\n",
    "    \n",
    "    y_train_pred_scaled = model.predict(X_train)\n",
    "\n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_train = scaler_y.inverse_transform(y_train.reshape(-1, 1))                 \n",
    "\n",
    "    # Calculate MSE and R-squared on the training set\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f'Mean Squared Error (Training): {mse_train}')\n",
    "    print(f'R-squared (Training): {r2_train}')\n",
    "\n",
    "    # Plot the real and predicted values for the first 100 test samples\n",
    "    \n",
    "    window_size = 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test.flatten()[:window_size], label='Real Values', color='blue')\n",
    "    plt.plot(y_pred.flatten()[:window_size], label='Predicted Values', color='red')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('velocity')\n",
    "    plt.ylim(0, 127)\n",
    "    plt.legend()\n",
    "    plt.savefig('LSTM-4_velocity_high_res.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41dd2f",
   "metadata": {},
   "source": [
    "## RNN velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_LSTM_RNN = df_complete_LSTM_RNN_ref.copy()\n",
    "\n",
    "# Select features and target\n",
    "\n",
    "features = ['note_numb', 'onbeat', 'PC', 'SC', 'HS', 'hammer-on', 'pull-off', 'bending', 'delta_onset_ms-1', 'velocity-1']\n",
    "target = 'velocity'\n",
    "\n",
    "X = df_complete_LSTM_RNN[features].values\n",
    "y = df_complete_LSTM_RNN[target].values\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Create sequences\n",
    "\n",
    "def create_sequences(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 1\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# Remove sequences containing rows where 'ex_note_numb' == 2\n",
    "indices_to_remove = df_complete_LSTM_RNN.index[df_complete_LSTM_RNN['ex_note_numb'] == 2].tolist()\n",
    "\n",
    "filtered_X_seq = []\n",
    "filtered_y_seq = []\n",
    "\n",
    "for i in range(len(X_seq)):\n",
    "    sequence_indices = list(range(i, i + time_steps + 1))\n",
    "    if not any(idx in indices_to_remove for idx in sequence_indices):\n",
    "        filtered_X_seq.append(X_seq[i])\n",
    "        filtered_y_seq.append(y_seq[i])  \n",
    "        \n",
    "filtered_X_seq = np.array(filtered_X_seq)\n",
    "filtered_y_seq = np.array(filtered_y_seq)\n",
    "\n",
    "if filtered_X_seq.size == 0:\n",
    "    print(\"No sequences remaining after filtering.\")\n",
    "else:\n",
    "    X_filtered = filtered_X_seq.reshape(filtered_X_seq.shape[0], time_steps, -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_y_seq, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # RNN model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=40, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Add Early Stopping\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    epochs_used = len(history.epoch)\n",
    "    print(f\"Number of epochs used: {epochs_used}\")\n",
    "\n",
    "    # Test set predict\n",
    "    \n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))       \n",
    "\n",
    "    # Calculate MSE and R-squared on the test set\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Test): {mse_test}')\n",
    "    print(f'R-squared (Test): {r2_test}')\n",
    "\n",
    "    # Train set predict\n",
    "    \n",
    "    y_train_pred_scaled = model.predict(X_train)\n",
    "\n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_train = scaler_y.inverse_transform(y_train.reshape(-1, 1))                 \n",
    "\n",
    "    # Calculate MSE and R-squared on the training set\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f'Mean Squared Error (Training): {mse_train}')\n",
    "    print(f'R-squared (Training): {r2_train}')\n",
    "\n",
    "    # Plot the real and predicted values for the first 100 test samples\n",
    "    window_size = 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test.flatten()[:window_size], label='Real Values', color='blue')\n",
    "    plt.plot(y_pred.flatten()[:window_size], label='Predicted Values', color='red')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('velocity')\n",
    "    plt.ylim(0, 127)\n",
    "    plt.legend()\n",
    "    plt.savefig('RNN_velocity_high_res.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965453d",
   "metadata": {},
   "source": [
    "## RNN velocity 4 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea14af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_LSTM_RNN = df_complete_LSTM_RNN_ref.copy()\n",
    "\n",
    "# Select features and target\n",
    "\n",
    "features = ['ex_note_numb', 'note_numb', 'onbeat', 'PC', 'SC', 'HS', 'hammer-on', 'pull-off', 'bending', 'delta_onset_ms-1', 'velocity-1']\n",
    "target = 'velocity'\n",
    "\n",
    "X = df_complete_LSTM_RNN.drop(columns=['ex_note_numb'])[features[1:]].values\n",
    "y = df_complete_LSTM_RNN[target].values\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Save the scalers to disk\n",
    "\n",
    "joblib.dump(scaler_X, 'scaler_X_velocity.pkl')\n",
    "joblib.dump(scaler_y, 'scaler_y_velocity.pkl')\n",
    "\n",
    "# Create sequences\n",
    "\n",
    "def create_sequences(X, y, time_steps=4):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 4\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# Remove sequences containing rows where 'ex_note_numb' == 2, 3, 4, or 5\n",
    "\n",
    "indices_to_remove = df_complete_LSTM_RNN.index[df_complete_LSTM_RNN['ex_note_numb'].isin([2, 3, 4, 5])].tolist()\n",
    "\n",
    "filtered_X_seq = []\n",
    "filtered_y_seq = []\n",
    "\n",
    "for i in range(len(X_seq)):\n",
    "    sequence_indices = list(range(i, i + time_steps + 1))\n",
    "    if not any(idx in indices_to_remove for idx in sequence_indices):\n",
    "        filtered_X_seq.append(X_seq[i])\n",
    "        filtered_y_seq.append(y_seq[i])  \n",
    "        \n",
    "filtered_X_seq = np.array(filtered_X_seq)\n",
    "filtered_y_seq = np.array(filtered_y_seq)\n",
    "\n",
    "if filtered_X_seq.size == 0:\n",
    "    print(\"No sequences remaining after filtering.\")\n",
    "else:\n",
    "    X_filtered = filtered_X_seq.reshape(filtered_X_seq.shape[0], time_steps, -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_y_seq, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # RNN model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=40, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Add Early Stopping\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    epochs_used = len(history.epoch)\n",
    "    print(f\"Number of epochs used: {epochs_used}\")\n",
    "\n",
    "    # Test set predict\n",
    "    \n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))       \n",
    "\n",
    "    # Calculate MSE and R-squared on the test set\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Test): {mse_test}')\n",
    "    print(f'R-squared (Test): {r2_test}')\n",
    "\n",
    "    # Train set predict\n",
    "    \n",
    "    y_train_pred_scaled = model.predict(X_train)\n",
    "\n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_train = scaler_y.inverse_transform(y_train.reshape(-1, 1))                 \n",
    "\n",
    "    # Calculate MSE and R-squared on the training set\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f'Mean Squared Error (Training): {mse_train}')\n",
    "    print(f'R-squared (Training): {r2_train}')\n",
    "    \n",
    "    # Export the model for offline use\n",
    "    \n",
    "    model.save('RNN-4_regressor_velocity.h5')\n",
    "\n",
    "    # Plot the real and predicted values for the first 100 test samples\n",
    "    \n",
    "    window_size = 100\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test.flatten()[:window_size], label='Real Values', color='blue')\n",
    "    plt.plot(y_pred.flatten()[:window_size], label='Predicted Values', color='red')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('velocity')\n",
    "    plt.ylim(0, 127)\n",
    "    plt.legend()\n",
    "    plt.savefig('RNN-4_velocity_high_res.png', dpi=300)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
